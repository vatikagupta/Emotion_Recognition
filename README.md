## Facial_Emotion_Recognition using Deep Learning

The dataset used in this project is downloaded four different sources namely CK+ (Cohn Kanade), FERG-DB, VISGRAF Faces DB and JAFFE (Japanese Female Facial Expression) DB. Facial Expression Recognition usually performed in four-stages consisting of pre-processing, face detection, feature extraction, and expression classification. In this project deep learning methods (convolutional neural networks) are applied to identify the key seven human emotions: anger, disgust, fear, happiness, sadness, surprise and neutrality.

#### Overview
The model can be used for the prediction of expressions of both still images and real time video. However, in both the cases we have to provide image to the model. In case of real time prediction, the image should be taken at any frame in time and fed to the model for prediction of expression. The system automatically detects the face using HAAR cascade then it crops it and resize the image to a specific size and give it to the model for prediction. The model will generate seven probability values corresponding to seven expressions. The highest probability value to the corresponding expression will be the predicted expression for that image.
However, the goal here is to predict the human expressions, but the model is trained on both human and animated images. Since, there are  approximately 1500 human images which are very less to make a good model, so it took approximately 9000 animated images and leverage those animated images for training the model and ultimately do the prediction of expressions on human images.
For better prediction it is decided to keep the size of each image 350âˆ—350.

